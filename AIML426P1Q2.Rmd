---
title: "AIML426 Project 1 Q2"
author:  Chad Kakau
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
library(reticulate)
```

```{python importLibraries, include=FALSE}
import pandas as pd
import numpy as np
import feat_select as fs
import accuracies as ac

```

```{python wrapperExperiments, include=FALSE}
# test the wrapper function
WrapperGA = ac.changing_run(func = fs.main,
                         params = "FEAT_SEL = 'Wrapper'",
                         paths = ['wbcd.data', 'sonar.data'],
                         feat_names = ['wbcd.names', 'sonar.names'],
                         n = 5)  
```

```{python filterExperiments, include=FALSE}
# test the filter function
FilterGA = ac.changing_run(func = fs.main,
                        paths = ['wbcd.data', 'sonar.data'],
                        feat_names = ['wbcd.names', 'sonar.names'], 
                        n = 5)  
```

```{python readInData, include=FALSE}

feat_names_wbcd = pd.read_csv('wbcd.names', sep = ":", skiprows = [0], names = ['feature', 'type']) 
feat_names_wbcd.loc[len(feat_names_wbcd)+1, ['feature', 'type']] = ['class', 'discrete']
raw_data_wbcd = pd.read_csv('wbcd.data', index_col=False, names = [feat for feat in feat_names_wbcd.loc[:, 'feature']]) 


feat_names_sonar = pd.read_csv('sonar.names', sep = ":", skiprows = [0], names = ['feature', 'type'])
feat_names_sonar.loc[len(feat_names_sonar)+1, ['feature', 'type']] = ['class', 'discrete']
raw_data_sonar = pd.read_csv('sonar.data', index_col=False, names = [feat for feat in feat_names_sonar.loc[:, 'feature']]) 
    

X_wbcd = raw_data_wbcd.iloc[:, :len(feat_names_wbcd)]
y_wbcd = raw_data_wbcd['class']

X_sonar = raw_data_sonar.iloc[:, :len(feat_names_sonar)]
y_sonar = raw_data_sonar['class']


cols = ['wbcd', 'sonar']
ind = range(len(FilterGA[2][0]))


Filter_times = pd.DataFrame(columns = cols, index = ind)
Filter_accuracies = pd.DataFrame(columns = cols, index = ind)
Wrapper_times = pd.DataFrame(columns = cols, index = ind)
Wrapper_accuracies = pd.DataFrame(columns = cols, index = ind)

X = [X_wbcd, X_sonar]
y = [y_wbcd, y_sonar]


for i,_ in enumerate(Filter_times.columns):
  for j, _ in enumerate(FilterGA[2][i]):
    Filter_times.iloc[j,i] = FilterGA[2][i][j].seconds
    Filter_accuracies.iloc[j, i] = ac.accuracy_of_selected_features(ac.selected_features(ac.best_in_population(FilterGA[3][i][j]), X[i]), y[i])
    Wrapper_times.iloc[j, i] = WrapperGA[2][i][j].seconds
    Wrapper_accuracies.iloc[j,i] = ac.accuracy_of_selected_features(ac.selected_features(ac.best_in_population(WrapperGA[3][i][j]), X[i]), y[i]) 
    
sets = [Filter_times, Filter_accuracies, Wrapper_times, Wrapper_accuracies] #  

for set in sets:
  set.loc[len(set['wbcd']), :] = np.mean(set, axis = 0)
  set.loc[len(set['wbcd']), :] = np.std(set, axis =0)
  set.index = ['run1', 'run2', 'run3', 'run4', 'run5', 'mean', 'std_dev']
  
Processing_times_seconds = pd.DataFrame(
  {'FilterGA_wbcd': Filter_times['wbcd'], 
  'FilterGA_sonar': Filter_times['sonar'],
  'Wrapper_wbcd': Wrapper_times['wbcd'],
  'Wrapper_sonar': Wrapper_times['sonar']})
  
Accuracies = pd.DataFrame(
  {'FilterGA_wbcd': Filter_accuracies['wbcd'], 
  'FilterGA_sonar': Filter_accuracies['sonar'],
  'Wrapper_wbcd': Wrapper_accuracies['wbcd'],
  'Wrapper_sonar': Wrapper_accuracies['sonar']})
```

# AIML426 Project 1 Q2  

## Genetic Algorithm for Feature Selection  

Genetic algorithm can be used for feature selection, given $N$ features, each feature selection result can be represented as a $N$-dimensional binary list $X=(x_1, ..., x_n)$, where $x_i=1$ means the feature $i$ is selected and $x_i=0$ otherwise.  

### Problem description  

Take a dataset with $N$ features and determine the optimal selection of features for fitting a good predictive model.  The task is to build a Genetic Algorithm to perform feature selection, by selecting the fewest features that provide good classification.  The task requires two approaches:  

  - __Filter function__:  where the fitness evaluation is conducted without a classifier function  
  - __Wrapper function__:  where the fitness evaluation is conducted by assessing the classification accuracy of the features when used with a classification model.  
  
### evaluation function:  FilterGA  

The Filter function compares average mutual gain information per feature.  The evaluation function computes the information gain for the subset of features for an individual (i.e. features where $x_i = 1$) and then averages that information gain across the selected features, to give an average information gain per feature.  The sklearn.feature_selection.mutual_info_classif function allows for identification of discrete variables and can handle continuous variables.  

$$
\begin{aligned}
\text{Fit}_{avg IG} & = \frac{I(Y;X)}{m}, \text{ with } m = \text{no. of features in X}\\
 \\
 I(Y;X)& = H(X)+H(Y)-H(X,Y)\\
\text{where } H(Y) & = -\sum_y p(y)*log_2 p(y),\\
H(X) & = -\sum_y p(x)*log_2 p(x),\\
 H(X,Y) & = -\sum_{x,y} p(x, y)*log_2 p(x, y),\\
\end{aligned}
$$

Average information gain per feature has a maximising objective.  Number of features has a minimising objective. 

I chose the mutual gain approach because I thought it would be quicker to calculate and was so confused when the results took longer than the Wrapper method.  I figured out that because I was using the sklearn.feature_selection.mutual_info_classif function and this running a full modedlling process for each individual.  In the end I calculated the entropies for each class $(H(Y))$, each feature $(H(X_i))$, and the joint entropies for each feature and class $(H(X_i, Y))$and stored those values at read-in.  Using this method, signficiantly reduced the time for calculating mutual gain for each individual.

### evaluation function:  Wrapper

The Wrapper function uses the sklearn.neighbors.KNeighborsClassifier function to fit a model to the reduced feature set and determines accuracy of that fitted model against a test set.  The K-Neighbors Classifier is set to $k = 2$.

I chose this method because I already knew how many classes there were in the categorical dataset.  Even without knowing, I could have easily established the number of classes by using something like the pandas.Series().values_count() function to determine counts of each class and the number of classes.  That means I could modify the code to accept multi-class objectives.

### Parameter settings  

I reused many of the same parameters from the knapsack problem because of the similarities with this feature selection problem.  I considered using different methods for selection, crossover and mutation, but there weren't any compelling reasons (i.e. performance differences were driven primarily by the use of the FilterGA vs the WrapperGA and that was down to the greater resource required for fitting the model for each individual, even if that individual had been modelled already).

As well as retaining the same methods as in the knapsack problem (Uniform crossover, FlipBit mutation, Elitism selection, and the MuPlusLambda), I also retained the same values for stochastic processes:  
  - CXPB = 0.6 - probability an individual would produced by crossover  
  - MUTPB = 0.4 - probability an individual would undergo mutation  
  - INDPB = 0.4 - probability an individual bit being crossed over between parents (for crossover) or a bit being flipped (for mutation)  
  - k = 2 for KNeighbors classifier used in wrapper evaluation  
  - bins = 10 - number of bins for discretisation of continuous features.  
  
The changes I made were:  
  - removed bias for producing mostly empty individuals in the first generation  
  - reduced the size of the first population to the number of features for the dataset (i.e. 30 for the wbcd.data, 60 for the sonar.data set), and subsequent populations were the same size.
  
These changes were driven by the excessive time taken for running the Wrapper function with on large populations.  I retained 50 generations for the number of evolutions.  

### Results and Discussion

#### Computational time  

The computational time was much higher for the WrapperGA method than for the FilterGA method.  This should come as no surprise because of the implemented approaches:  
  - FilterGA method calculates individual (i.e. $H(Y)$, $H(X_i)$) and shared entropies (i.e. $H(X_i Y)$ once, reducing the the computation of mutual gain to the summation of scalar values  
  - WrapperGA method fits a full model (with reduced features) for each individual, which takes more processing per individual.  
  - Neither method incorporates a memory function (i.e. each individual's fitness is re-computed, even if that individual is a duplicate of one that has already occurred in the population), and this has a greater cumulative effect for the WrapperGA function than for the FilterGA function.  

Processing times: 
```{python processingTimes, echo=FALSE}
Processing_times_seconds
```

The FilterGA method takes an average of 3 seconds to run for both datasets, with no variance between runs.  In contrast, the Wrapper method took an average of 106 seconds for the wbcd data set and 97 seconds for the sonar data, with standard deviation of .73 and .36 seconds respectively. 
  
#### accuracy of selected features

I trained the selected features represented by the best individuals produced from each method (FilterGA and WrapperGA) using the sklearn.tree.DecisionTreeClassifier function.  The decision tree classifier offers a reasonably efficient algorithm.

```{python accuracies, echo=FALSE}
Accuracies
```

The FilterGA method produced mean accuracy of `r py$Accuracies['mean','FilterGA_wbcd']` on the wbcd data and `r py$Accuracies['mean','FilterGA_sonar']` on the sonar data.  The WrapperGA method produced mean accuracy of `r py$Accuracies['mean','Wrapper_wbcd']` on the wbcd data and `r py$Accuracies['mean','Wrapper_sonar']` on the sonar data.  This indicates that the Filter method selected a feature set with comparable performance to the Wrapper method for both datasets.  

When considered in conjunction with time taken for each method, the lower time cost for the FilterGA method seems like a significantly more efficient method with comparable accuracy, than the Wrapper method.

```{python accuracyVsFitness, echo=FALSE}
best_Wwbcd = [ac.best_in_population(pop).fitness.values[0] for pop in WrapperGA[3][0]]
best_Wsonar= [ac.best_in_population(pop).fitness.values[0] for pop in WrapperGA[3][1]]

fit_acc_comparison = pd.DataFrame(
  {'wbcd accuracy': Wrapper_accuracies.loc['run1':'run5', 'wbcd'],
  'wbcd fitness': best_Wwbcd,
  'sonar accuracy': Wrapper_accuracies.loc['run1':'run5', 'sonar'],
  'sonar fitness': best_Wsonar}
)

fit_acc_comparison

```

Comparing the WrapperGA fitness value against the accuracy for the individual runs shows generally better fitness values than accuracy for the wbcd data, and markedly better fitness values than accuracy for the sonar data.  This could be caused by the different classification models used (K Nearest Neighbors, with k=2, for the fitness function and Decision Tree for conducting the classification accuracy).  To eliminate this doubt, we could conduct the experiment using the same algorithm in the fitness and classification assessments.

